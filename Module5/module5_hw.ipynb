{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58adcffb-d5f4-42fa-a13d-c5a1619e6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af8aa40-90b8-4786-9957-7748c851474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = '/home/realadmin/.google/creds/zcamp-spark-28a6151fa616.json'\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('test') \\\n",
    "    .set(\"spark.jars\", \"/home/realadmin/spark/spark-3.5.5-bin-hadoop3/jars/gcs-connector-hadoop3-latest.jar\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2e84025-7843-49ae-ac2e-7ce3c6eacd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/07 22:35:54 WARN Utils: Your hostname, biccboii resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/03/07 22:35:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "25/03/07 22:35:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc757db5-3c0e-4a69-ae8f-d43a10fbfb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9097d2f-6ccb-4ebd-b4d5-3b7cb811ab5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.5'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db720d89-3878-4897-b55f-4e921d90c556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('gs://zcamp-nyc-taxi/pq/yellow/2024/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfc5f3c7-6d28-4a92-b8aa-2ea1bbe26f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ef906fe-18c6-4b37-bade-a5f3d80fb104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.write.parquet('gs://zcamp-nyc-taxi/yellow/2024/10/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11c5856f-0306-4a43-84e9-4438bb3dab83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge',\n",
       " 'Airport_fee']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "118b3f40-62b0-4a8b-9b9c-04f41ad122ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02ca21db-04c0-48f6-aa19-b5f2408d3c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2024-10-07 16:40:43|  2024-10-07 18:10:56|              1|         14.8|        99|                 N|         127|         225|           1|       47.5|  0.0|    0.5|       0.0|        6.94|                  0.0|       54.94|                 0.0|        0.0|\n",
      "|       2| 2024-10-04 14:17:41|  2024-10-04 14:26:47|              1|          1.1|         1|                 N|         113|         211|           1|        9.3|  0.0|    0.5|      2.66|         0.0|                  1.0|       15.96|                 2.5|        0.0|\n",
      "|       2| 2024-10-01 11:17:28|  2024-10-01 11:32:18|              1|         4.63|         1|                 N|         231|         170|           1|       21.9|  0.0|    0.5|      5.18|         0.0|                  1.0|       31.08|                 2.5|        0.0|\n",
      "|       1| 2024-10-08 17:12:07|  2024-10-08 17:35:56|              1|          2.4|         1|                 N|         236|         100|           1|       19.8|  5.0|    0.5|      5.25|         0.0|                  1.0|       31.55|                 2.5|        0.0|\n",
      "|       1| 2024-10-01 15:37:08|  2024-10-01 15:54:23|              1|          2.1|         1|                 N|         237|          75|           1|       16.3|  2.5|    0.5|      4.05|         0.0|                  1.0|       24.35|                 2.5|        0.0|\n",
      "|       1| 2024-10-09 10:14:04|  2024-10-09 10:28:13|              1|          1.7|         1|                 N|         161|         234|           1|       12.8|  2.5|    0.5|      3.35|         0.0|                  1.0|       20.15|                 2.5|        0.0|\n",
      "|       2| 2024-10-04 17:08:38|  2024-10-04 18:03:10|              1|        17.42|         1|                 N|         132|          17|           1|       75.1|  2.5|    0.5|     19.77|         0.0|                  1.0|      100.62|                 0.0|       1.75|\n",
      "|       2| 2024-10-05 01:27:22|  2024-10-05 01:40:37|              1|         1.88|         1|                 N|         148|         137|           1|       13.5|  1.0|    0.5|       3.7|         0.0|                  1.0|        22.2|                 2.5|        0.0|\n",
      "|       2| 2024-10-05 23:50:45|  2024-10-06 00:00:32|              1|         1.06|         1|                 N|          79|         211|           1|       10.0|  1.0|    0.5|       2.0|         0.0|                  1.0|        17.0|                 2.5|        0.0|\n",
      "|       2| 2024-10-02 14:31:14|  2024-10-02 14:45:59|              1|         2.88|         1|                 N|         231|         246|           2|       17.0|  0.0|    0.5|       0.0|         0.0|                  1.0|        21.0|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "    SELECT * FROM trips LIMIT 10;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a965aa1-44d7-4bf2-b469-278c20ab5f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "128893"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(F.to_date(df.tpep_pickup_datetime) == \"2024-10-15\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73048c27-0a86-4155-ac88-edc1b5051377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:==============================================>         (10 + 2) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  128893|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_15th = spark.sql(\"\"\"\n",
    "    SELECT COUNT(1) FROM trips\n",
    "    WHERE CAST(tpep_pickup_datetime AS Date) = '2024-10-15'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb67022c-6279-4c79-8b64-fec12f405566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:===================================================>    (11 + 1) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|length|\n",
      "+------+\n",
      "|   162|\n",
      "+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_long = spark.sql(\"\"\"\n",
    "    SELECT DATEDIFF(hour,tpep_pickup_datetime, tpep_dropoff_datetime) as length\n",
    "    FROM trips\n",
    "    ORDER BY length DESC\n",
    "    LIMIT 1;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7997708b-317f-4150-85ea-893d2b4a05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.csv('taxi_zone_lookup.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29935b19-3245-4e68-826f-d80db6e1e05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LocationID', 'Borough', 'Zone', 'service_zone']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cb19ce9-7e47-4179-ae40-d9865ac544c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.createOrReplaceTempView('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f14631af-ba72-4514-baf3-a076aabf8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_zones = df.join(df_zones, df.PULocationID == df_zones.LocationID).drop('LocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34308a9e-d3cf-46d2-99cd-289b1d6bf09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge',\n",
       " 'Airport_fee',\n",
       " 'Borough',\n",
       " 'Zone',\n",
       " 'service_zone']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trips_zones.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58ac4af7-14b6-4f7c-9a80-af64dbf0afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_zones.createOrReplaceTempView('trips_zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c519974-330a-4f8c-a8c1-87e063e018b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:======================================>                  (8 + 4) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-------------+\n",
      "|PULocationID|                Zone|total_pickups|\n",
      "+------------+--------------------+-------------+\n",
      "|         105|Governor's Island...|            1|\n",
      "+------------+--------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_least = spark.sql(\"\"\"\n",
    "    SELECT PULocationID\n",
    "    ,Zone\n",
    "    ,COUNT(1) AS total_pickups\n",
    "    FROM trips_zones\n",
    "    GROUP BY PULocationID, Zone\n",
    "    ORDER BY total_pickups ASC\n",
    "    LIMIT 1;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d087a26-acd6-41a4-969f-225bfa83289f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
